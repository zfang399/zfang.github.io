<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Andy Fang</title>
  
  <meta name="author" content="Andy Fang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="imgs/icon.jpeg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhaoyuan &ldquo;Andy&rdquo; Fang</name>
              </p>
              <p>I'm an MS student in Robotics at <a href="https://www.ri.cmu.edu/">Carnegie Mellon University</a>, working with <a href="https://www.cs.cmu.edu/~katef/">Prof. Katerina Fragkiadaki</a> on Computer Vision and Machine Learning.
              </p>
              <p>
                I got my B.S. from the <a href="https://www.nd.edu/">University of Notre Dame</a>, majoring in Electrical Engineering and Maths. During my undergrad, I am fortunate to have spent great time working with <a href="https://engineering.nd.edu/faculty/adam-czajka/">Prof. Adam Czajka</a> and <a href="https://www3.nd.edu/~kwb/">Prof. Kevin Bowyer</a>. 
                I was also lucky to have interned with <a href="https://davheld.github.io/">Prof. David Held</a> and collaborated with <a href="http://people.csail.mit.edu/hangzhao/">Prof. Hang Zhao</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zfang399@gmail.com">Email</a> &nbsp/&nbsp
                <a href="resource/Fang_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=lgHhJQ8AAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/zfang399/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="imgs/me.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="imgs/me.jpg"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in and currently working on computer vision and machine learning. During my undergrad, I worked mostly on Biometrics, while my first research experience was on <a href="https://aip.scitation.org/doi/abs/10.1063/1.4996213?journalCode=apl&">nanophotonics</a>. For a full list please see Google Scholar. Some works can be found below (* = equal contribution).
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="robustiris_stop()" onmouseover="robustiris_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='robustiris_image'>
                  <img src='imgs/robustiris_before.png' width="160"></div>
                <img src='imgs/robustiris_before.png' width="160">
              </div>
              <script type="text/javascript">
                function robustiris_start() {
                  document.getElementById('robustiris_image').style.opacity = "1";
                }

                function robustiris_stop() {
                  document.getElementById('robustiris_image').style.opacity = "0";
                }
                robustiris_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2002.09137">
                <papertitle>Robust Iris Presentation Attack Detection Fusing 2D and 3D Information</papertitle>
              </a>
              <br>
              <strong>Zhaoyuan Fang</strong>,
              <a href="https://engineering.nd.edu/faculty/adam-czajka/">Adam Czajka</a>,
              <a href="https://www3.nd.edu/~kwb/">Kevin W. Bowyer</a>
              <br>
              <em>IEEE Transactions on Information Forensics and Security (T-IFS)</em>, 2020
              <br>
              <a href="https://github.com/CVRL/RaspberryPiOpenSourceIris">code</a> /
              <a href="https://www.youtube.com/watch?v=CbOgnb6-2-A">video</a>
              <br>
              <p></p>
              <p>
              Experiments show that 2D textual and 3D shape features are complementary for iris presentation attack detecttion and fusing then together results in robust performance under various open-set testing scenarios.
              </p>
            </td>
          </tr>  

          <tr onmouseout="openiris_stop()" onmouseover="openiris_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='openiris_image'>
                  <img src='imgs/openiris_before.png' width="160"></div>
                <img src='imgs/openiris_before.png' width="160">
              </div>
              <script type="text/javascript">
                function openiris_start() {
                  document.getElementById('openiris_image').style.opacity = "1";
                }

                function openiris_stop() {
                  document.getElementById('openiris_image').style.opacity = "0";
                }
                openiris_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2008.08220">
                <papertitle>Open Source Iris Recognition Hardware and Software with Presentation Attack Detection</papertitle>
              </a>
              <br>
              <strong>Zhaoyuan Fang</strong>,
              <a href="https://engineering.nd.edu/faculty/adam-czajka/">Adam Czajka</a>
              <br>
              <em>IEEE International Joint Conference on Biometrics (IJCB)</em>, 2020
              <br>
              <a href="https://github.com/CVRL/RaspberryPiOpenSourceIris">code</a> /
              <a href="https://www.youtube.com/watch?v=K95QRC4PxAA">video</a>
              <br>
              <p></p>
              <p>
              An open source, low-cost, fast and accuract iris recognition protoype with presentation attack detection based on Raspberry-Pi and Python.
              </p>
            </td>
          </tr>   

          <tr onmouseout="gsir_stop()" onmouseover="gsir_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='gsir_image'>
                  <img src='imgs/gsir_before.png' width="160"></div>
                <img src='imgs/gsir_before.png' width="160">
              </div>
              <script type="text/javascript">
                function gsir_start() {
                  document.getElementById('gsir_image').style.opacity = "1";
                }

                function gsir_stop() {
                  document.getElementById('gsir_image').style.opacity = "0";
                }
                gsir_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580494.pdf">
                <papertitle>GSIR: Generalizable 3D Shape Interpretation and Reconstruction</papertitle>
              </a>
              <br>
              <a href="http://www.jianrenw.com/">Jianren Wang</a>,
              <strong>Zhaoyuan Fang</strong>
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2020
              <br>
              <a href="http://www.jianrenw.com/gsir/">project page</a> /
              <a href="https://www.youtube.com/watch?v=cAWjk4U7ehs&t">video</a>
              <br>
              <p></p>
              <p>
              A model designed for joint shape interpretation and reconstruction improves performance on both tasks.
              </p>
            </td>
          </tr>  

          <tr onmouseout="alignnet_stop()" onmouseover="alignnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='alignnet_image'>
                  <img src='imgs/alignnet_before.png' width="160"></div>
                <img src='imgs/alignnet_before.png' width="160">
              </div>
              <script type="text/javascript">
                function alignnet_start() {
                  document.getElementById('alignnet_image').style.opacity = "1";
                }

                function alignnet_stop() {
                  document.getElementById('alignnet_image').style.opacity = "0";
                }
                alignnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Wang_AlignNet_A_Unifying_Approach_to_Audio-Visual_Alignment_WACV_2020_paper.pdf">
                <papertitle>AlignNet: A Unifying Approach to Audio-Visual Alignment</papertitle>
              </a>
              <br>
              <a href="http://www.jianrenw.com/">Jianren Wang*</a>,
              <strong>Zhaoyuan Fang*</strong>,
              <a href="http://people.csail.mit.edu/hangzhao/">Hang Zhao</a>
              <br>
              <em>IEEE Winter Conf. on Applications of Computer Vision (WACV)</em>, 2020
              <br>
              <a href="http://www.jianrenw.com/AlignNet/">project page</a> /
              <a href="https://github.com/zfang399/AlignNet">code</a> /
              <a href="https://www.youtube.com/watch?v=UfOJiyVl48A">video</a>
              <br>
              <p></p>
              <p>
              End-to-end dense correspondence between each frame of a video and an audio can be learned with a model with simple and well-established principles: attention, pyramidal processing, warping, and affinity function.
              </p>
            </td>
          </tr>  

          <tr onmouseout="photopad_stop()" onmouseover="photopad_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='photopad_image'>
                  <img src='imgs/photopad_before.png' width="160"></div>
                <img src='imgs/photopad_before.png' width="160">
              </div>
              <script type="text/javascript">
                function photopad_start() {
                  document.getElementById('photopad_image').style.opacity = "1";
                }

                function photopad_stop() {
                  document.getElementById('photopad_image').style.opacity = "0";
                }
                photopad_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1811.07252">
                <papertitle>Iris Presentation Attack Detection Based on Photometric Stereo Features</papertitle>
              </a>
              <br>
              <a href="https://engineering.nd.edu/faculty/adam-czajka/">Adam Czajka</a>,
              <strong>Zhaoyuan Fang</strong>,
              <a href="https://www3.nd.edu/~kwb/">Kevin W. Bowyer</a>
              <br>
              <em>IEEE Winter Conf. on Applications of Computer Vision (WACV)</em>, 2019
              <br>
              <a href="https://github.com/CVRL/PhotometricStereoIrisPAD">code</a>
              <br>
              <p></p>
              <p>
              Traditional 3D reconstruction technique Photometric Stereo provides surprisingly simple but effective features to classify real iris images from fake ones.
              </p>
            </td>
          </tr>  
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc.</heading>
              <p>
                If you're bored, here's my favorite song of: 
                <a href="https://www.youtube.com/watch?v=URRimPZBHf8">08/21</a>, 
                <a href="https://www.youtube.com/watch?v=dtq-s0XrUbg">07/21</a>,
                <a href="https://www.youtube.com/watch?v=9T_uq_HpfyQ">06/21</a>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                Awesome template borrowed from <a href="https://jonbarron.info/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
    <script type="text/javascript" id="clustrmaps" 
            src="//cdn.clustrmaps.com/map_v2.js?d=7yAjl-dl1Pss6n_YucxpbFeneOTwxAun1YnZJWnczsE&cl=ffffff&w=a"></script>
  </table>
</body>

</html>
